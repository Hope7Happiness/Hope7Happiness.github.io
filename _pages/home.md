---
title: ""
layout: single
author_profile: true
permalink: /
---

# About Me

I am an undergraduate student in MIT Class of 2028, majoring in Physics (Course 8). I am also planning to double-major in Artificial Intelligence and Decision Making (Course 6-4).

I attended high school in China, where I studied Physics competition, and won a gold medal in the 53rd International Physics Olympiad (IPhO). After that, I have taken a preparatory year at IIIS, Tsinghua University (also known as the Yao Class). During my period at IIIS, I built a foundation in Machine Learning and Deep Learning as well as proficiency in PyTorch. I also developed a solid understanding of the mathematical foundations related to computer science and artificial intelligence.

Although I am just a beginner, I am eager to explore various research opportunities. I was an [UROP](https://urop.mit.edu/) student at Professor [Kaiming He](https://people.csail.mit.edu/kaiming/)'s group from September 2024 to December 2024, where I did research on generative models together with my colleagues [Zhicheng Jiang](https://jzc-2007.github.io) and [Qiao Sun](https://qiaosungithub.github.io).

I am currently thinking on my future plans, though I donâ€™t have a clear direction yet. I really enjoy talking with people who share similar interests or simply exchanging personal stories. Feel free to reach out if you'd like to connect!

My resume is linked [here](/assets/pdf/cv.pdf).

## Selected Projects

- [**Speeding Up Diffusion Models with One-step Generators**](https://github.com/Hope7Happiness/6s978_project)

    <p style="font-size: 18px;">This is the final project for the seminar course <i>6.S978: Deep Generative Models</i> at MIT. In the project, we proposed a new method to speed up the training of diffusion models by using one-step generators. On toy experiments, this reduces NFE by half while maintaining the sample quality. We also wrote a <a href="https://hope7happiness.github.io/three_diff/">blog post</a>, explaining the motivation of the experiment from a higher perspective.</p>

- [**Knowledge Database**](https://github.com/Hidden-Hyperparameter/llm_project)

    <p style="font-size: 18px;">This is the project for the course <i>Introduction to Large Language Model Application</i> at IIIS, Tsinghua University. In the project, we apply LLMs to answer user questions given a folder containing documents as the context. We developed a tagging system, which make the search efficient even when the number of documents is large. We also support semantic search for multimodal documents, such as images and videos.</p>

- [**Deep Learning Study**](https://github.com/Hidden-Hyperparameter/DeepLearning)

    <p style="font-size: 18px;">In the repository, I tried to implement some classic and modern deep learning models from scratch. Instead of using extensive tricks and hyperparameter tuning, I tried to make each model implementation simple and easy to follow while giving reasonable results. I also tried to analyze what tricks are the most necessary for the model to work, so that I can find out the problem more quickly when a new model doesn't work as expected.
    <br><br>
    The repository is still under construction, and I will keep updating it with more models and analysis.</p>
